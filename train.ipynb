{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff3a0d-0c43-4065-9415-d6984a1b7e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801a34e-c02b-4eb2-abd3-2ca860d3cc3b",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# specify substep parameters for interactive run\n",
    "# this cell will be replaced during job run with the parameters from json within params subfolder\n",
    "substep_params={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b65680-0206-4bae-99d4-f3ce82167678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipeline and step parameters - do not edit\n",
    "from sinara.substep import get_pipeline_params, get_step_params\n",
    "pipeline_params = get_pipeline_params(pprint=True)\n",
    "step_params = get_step_params(pprint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9452dc47-ec58-4ba9-b2e2-a3f6aae3100e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define substep interface\n",
    "from sinara.substep import NotebookSubstep, ENV_NAME, PIPELINE_NAME, ZONE_NAME, STEP_NAME, RUN_ID, ENTITY_NAME, ENTITY_PATH, SUBSTEP_NAME\n",
    "\n",
    "substep = NotebookSubstep(pipeline_params, step_params, substep_params)\n",
    "\n",
    "substep.interface(\n",
    "    inputs =\n",
    "    [ \n",
    "      { STEP_NAME: \"data_prep\", ENTITY_NAME: \"train_dataset\"}, # train dataset from data_prep step\n",
    "      { STEP_NAME: \"data_prep\", ENTITY_NAME: \"val_dataset\"}, # val dataset from data_prep step\n",
    "    ],\n",
    "    tmp_entities = \n",
    "    [       \n",
    "       { ENTITY_NAME: \"train_dataset\" }, # temporary datasets for train on next substep\n",
    "       { ENTITY_NAME: \"val_dataset\" }, # temporary datasets for val on next substep\n",
    "       { ENTITY_NAME: \"classifier_train_work_dir\"}, # temporary working dir for next substep\n",
    "       { ENTITY_NAME: \"classifier_inference_files\"} # temporarily stored classifier files \n",
    "    ],\n",
    "    outputs = \n",
    "    [\n",
    "        { ENTITY_NAME: \"classifier_inference_files\"} # stored classifier files\n",
    "    ]\n",
    ")\n",
    "\n",
    "substep.print_interface_info()\n",
    "\n",
    "substep.exit_in_visualize_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3126b0-94ee-41ac-a8e7-bdebfefe5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify all notebook wide libraries imports here\n",
    "# Sinara lib imports is left in the place of their usage\n",
    "import os.path as osp\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils.models import ResNet18\n",
    "from utils.train_eval import init_params\n",
    "from utils.train_eval import train, test\n",
    "\n",
    "print(f\"{torch.__version__=}\")\n",
    "print(f\"{torchvision.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82e0092-9175-4cd5-b8f9-411191f8c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the version of libraries and checking the availability of the cuda kernel\n",
    "assert torch.cuda.is_available(), f\"Cuda not available\"\n",
    "\n",
    "device_id = torch.cuda.current_device()\n",
    "device_name = torch.cuda.get_device_name(device_id)\n",
    "print(f\"{device_name=}\")\n",
    "print(f\"{torch.cuda.device_count()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f483d-11ce-49a9-84c3-f0fb8baa6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run spark\n",
    "from sinara.spark import SinaraSpark\n",
    "from sinara.archive import SinaraArchive\n",
    "\n",
    "spark = SinaraSpark.run_session(0)\n",
    "archive = SinaraArchive(spark)\n",
    "SinaraSpark.ui_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a682f5ec-9070-4e03-b2cc-019ec629d843",
   "metadata": {},
   "source": [
    "### Loading cifar10 train and val datasets of images (from the previous step data_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e600d2c-141b-4211-84c2-a98fdbd0f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_inputs = substep.inputs(step_name = \"data_prep\")\n",
    "tmp_entities = substep.tmp_entities()\n",
    "\n",
    "archive.unpack_files_from_store_to_tmp(store_path=data_prep_inputs.train_dataset, tmp_entity_dir=tmp_entities.train_dataset)\n",
    "archive.unpack_files_from_store_to_tmp(store_path=data_prep_inputs.val_dataset, tmp_entity_dir=tmp_entities.val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaae8c5-ed61-4a30-949a-55c6afd08518",
   "metadata": {},
   "source": [
    "## Setting up the training and valuate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118e119e-c4f8-44ce-8f6f-babe24b992ea",
   "metadata": {},
   "source": [
    "### Defining basic variables for train and valuate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd653b62-59d9-4b83-b219-716b69baba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = step_params[\"train_params\"]\n",
    "val_params = step_params[\"val_params\"]\n",
    "\n",
    "MAX_IMAGE_SIZE = train_params['MAX_IMAGE_SIZE']\n",
    "MEAN_NORMALIZE = train_params['NORMALIZE'][\"mean\"]\n",
    "STD_NORMALIZE  = train_params['NORMALIZE'][\"std\"]\n",
    "\n",
    "EPOCH_COUNT       = train_params['EPOCH_COUNT']\n",
    "BATCH_TRAIN       = train_params['BATCH']\n",
    "WORKERS_TRAIN     = train_params['WORKERS']\n",
    "BATCH_VAL         = val_params['BATCH']\n",
    "WORKERS_VAL       = val_params['WORKERS']\n",
    "\n",
    "OPTIMIZER_LR           = train_params['OPTIMIZER_SGD'][\"learning_rate\"]\n",
    "OPTIMIZER_WEIGHT_DECAY = train_params['OPTIMIZER_SGD'][\"weight_decay\"]\n",
    "OPTIMIZER_MOMENTUM     = train_params['OPTIMIZER_SGD'][\"momentum\"]\n",
    "\n",
    "CHECKPOINT_INTERVAL = 5\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06049cd7-a9fe-43cd-8240-273be3bfca53",
   "metadata": {},
   "source": [
    "### Setting trasform augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466dac8-7d11-4efc-a5b3-dfdff968ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_transform_train = transforms.Compose([\n",
    "    transforms.Resize(size = (MAX_IMAGE_SIZE, MAX_IMAGE_SIZE)),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor = 2),\n",
    "    transforms.RandomRotation(degrees = 45),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=torch.tensor(MEAN_NORMALIZE)/255, std=torch.tensor(STD_NORMALIZE)/255),\n",
    "])\n",
    "\n",
    "torch_transform_val = transforms.Compose([\n",
    "    transforms.Resize(size = (MAX_IMAGE_SIZE, MAX_IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=torch.tensor(MEAN_NORMALIZE)/255, std=torch.tensor(STD_NORMALIZE)/255),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aff2dd-4f38-4930-9fe0-47b0593b8c70",
   "metadata": {},
   "source": [
    "### Setting pytorch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e07e50-4e9f-45ae-9023-a66725f65b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_train_dataset = torchvision.datasets.ImageFolder(root=tmp_entities.train_dataset, transform=torch_transform_train)\n",
    "torch_val_dataset = torchvision.datasets.ImageFolder(root=tmp_entities.val_dataset, transform=torch_transform_val)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch_train_dataset, batch_size=BATCH_TRAIN, shuffle=True, num_workers=WORKERS_TRAIN)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    torch_val_dataset, batch_size=BATCH_VAL, shuffle=False, num_workers=WORKERS_VAL)\n",
    "\n",
    "class_names = train_loader.dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7167d23f-dbaf-4d43-834c-36ac551237db",
   "metadata": {},
   "source": [
    "### Setting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb0f44-5030-4281-9c25-6b5e55ba626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_classifier = ResNet18(num_classes = len(class_names))\n",
    "net_classifier = net_classifier.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14853f5-e444-493d-9671-3016c8f9b2ef",
   "metadata": {},
   "source": [
    "### Setting loss function and optimizer and Initializing classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa37cb-8789-4635-9127-7da3267166f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net_classifier.parameters(), lr=OPTIMIZER_LR,\n",
    "                      momentum=0.9, weight_decay=OPTIMIZER_WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "init_params(net_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae00a2f-6230-4e50-8735-7e4b306b5e88",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start classifier training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd95162-04e9-4c90-a4c4-fdd96675bc8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "for epoch in range(EPOCH_COUNT):\n",
    "    \n",
    "    train(net=net_classifier, \n",
    "          criterion=criterion, \n",
    "          optimizer=optimizer, \n",
    "          loader=train_loader, \n",
    "          epoch=epoch,\n",
    "          device=DEVICE)\n",
    "    \n",
    "    val_acc = test(net=net_classifier, \n",
    "                    criterion=criterion, \n",
    "                    optimizer=optimizer, \n",
    "                    loader=val_loader, \n",
    "                    epoch=epoch,\n",
    "                    device=DEVICE)\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    if val_acc > best_acc:\n",
    "        print(f\"Saving best weights with acc={round(val_acc, 2)}\")\n",
    "        torch.save(net_classifier, osp.join(tmp_entities.classifier_train_work_dir, \"best_ckpt.pth\"))\n",
    "        best_acc = val_acc\n",
    "\n",
    "    if (epoch % (CHECKPOINT_INTERVAL-1) == 0) and (epoch > 0):\n",
    "        print(f\"Saving weights for epoch {epoch}\")\n",
    "        torch.save(net_classifier, osp.join(tmp_entities.classifier_train_work_dir, f\"ckpt_{epoch}.pth\"))\n",
    "        if osp.exists(osp.join(tmp_entities.classifier_train_work_dir, f\"latest_checkpoint.pth\")):\n",
    "            os.remove(osp.join(tmp_entities.classifier_train_work_dir, f\"latest_checkpoint.pth\"))\n",
    "        os.symlink(osp.join(tmp_entities.classifier_train_work_dir, f\"ckpt_{epoch}.pth\"),\n",
    "                   osp.join(tmp_entities.classifier_train_work_dir, f\"latest_checkpoint.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184db844-5828-4715-bf45-e96690211096",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Collecting obj_detect_inference_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832beb9f-ef9f-4ec0-a21a-91903f33b496",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Collecting test image from a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515856d5-2db0-46aa-b9df-32afddf69cff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_index = np.random.randint(0, len(torch_val_dataset))\n",
    "\n",
    "src_test_image_file_name = torch_val_dataset.imgs[image_index][0] \n",
    "if not osp.exists(src_test_image_file_name):\n",
    "    raise FileNotFoundError(f\"{src_test_image_file_name} was not found\")\n",
    "\n",
    "test_image_file_extension = Path(src_test_image_file_name).suffix\n",
    "dst_test_image_file_name = osp.join(tmp_entities.classifier_inference_files, f\"test{test_image_file_extension}\")\n",
    "\n",
    "shutil.copy(src_test_image_file_name, dst_test_image_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b22b1a0-a520-4cfb-908f-c6661af31b31",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Collecting train results\n",
    "(weights, config, test image) for subsequent transfer to other components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5eb6e1-50cd-4b53-b875-84a2130df072",
   "metadata": {},
   "source": [
    "Since during the training process intermediate weights of the neural network can be created (for example, for epochs 10, 20, 30, etc.)\n",
    "then it doesn't make much sense to copy all the intermediate files to another step in the pipeline.\n",
    "Therefore, we will copy the weights and the necessary configs into a separate directory and we will copy these files to outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cd9f9-d0b1-4c7b-bb7b-05710b62ff17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy files - last and best model weights and config model to finished dir\n",
    "best_chekpoint = osp.join(tmp_entities.classifier_train_work_dir, 'best_ckpt.pth')\n",
    "shutil.copy(best_chekpoint, \n",
    "            osp.join(tmp_entities.classifier_inference_files, osp.basename(best_chekpoint))\n",
    "           )\n",
    "\n",
    "last_checkpoint = osp.join(tmp_entities.classifier_train_work_dir, 'latest_checkpoint.pth')\n",
    "out_last_checkpoint = osp.join(tmp_entities.classifier_inference_files, \"latest_checkpoint.pth\")\n",
    "shutil.copy(last_checkpoint, out_last_checkpoint)\n",
    "\n",
    "with open(osp.join(tmp_entities.classifier_inference_files, 'categories.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(class_names, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa64369-efb6-45fe-8c2d-689ffadaa97a",
   "metadata": {},
   "source": [
    "### Save collected obj_detect_inference_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275ca57-1af4-461b-abb0-c6b5d2dcb145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = substep.outputs()\n",
    "archive.pack_files_from_tmp_to_store(tmp_entity_dir=tmp_entities.classifier_inference_files, store_path=outputs.classifier_inference_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a2604-bad8-40a4-8c39-b4cabb8ff56c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stop spark\n",
    "SinaraSpark.stop_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
